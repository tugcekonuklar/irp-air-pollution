{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Postdam PM2.5 Exponential Smooting Forcasting \n",
    "\n",
    "* Between 2013 and 2023, data collected by DEBB021 was used.\n",
    "* To increase the accuracy of PM2.5 data estimation, NO2, O3, SO2, PM10 pollutant gas data accepted by the EEA was added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import src\n",
    "import model_base as mb\n",
    "import exponential_smoothing as exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "* Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Timestamp</th>\n",
       "      <th>End_Timestamp</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>PM2.5-Pollutant</th>\n",
       "      <th>PM2.5-Value</th>\n",
       "      <th>PM2.5-Unit</th>\n",
       "      <th>PM2.5-Validity</th>\n",
       "      <th>PM2.5-Verification</th>\n",
       "      <th>PM10-Pollutant</th>\n",
       "      <th>...</th>\n",
       "      <th>O3-Pollutant</th>\n",
       "      <th>O3-Value</th>\n",
       "      <th>O3-Unit</th>\n",
       "      <th>O3-Validity</th>\n",
       "      <th>O3-Verification</th>\n",
       "      <th>SO2-Pollutant</th>\n",
       "      <th>SO2-Value</th>\n",
       "      <th>SO2-Unit</th>\n",
       "      <th>SO2-Validity</th>\n",
       "      <th>SO2-Verification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356998400</td>\n",
       "      <td>1357002000</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>71.04</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>43.17</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.18</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1357002000</td>\n",
       "      <td>1357005600</td>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>20.52</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>57.15</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.65</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1357005600</td>\n",
       "      <td>1357009200</td>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>9.56</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>63.31</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1357009200</td>\n",
       "      <td>1357012800</td>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>9.45</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>63.18</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1357012800</td>\n",
       "      <td>1357016400</td>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>13.02</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>61.70</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Timestamp  End_Timestamp                Start                  End  \\\n",
       "0       1356998400     1357002000  2013-01-01 00:00:00  2013-01-01 01:00:00   \n",
       "1       1357002000     1357005600  2013-01-01 01:00:00  2013-01-01 02:00:00   \n",
       "2       1357005600     1357009200  2013-01-01 02:00:00  2013-01-01 03:00:00   \n",
       "3       1357009200     1357012800  2013-01-01 03:00:00  2013-01-01 04:00:00   \n",
       "4       1357012800     1357016400  2013-01-01 04:00:00  2013-01-01 05:00:00   \n",
       "\n",
       "   PM2.5-Pollutant  PM2.5-Value PM2.5-Unit  PM2.5-Validity  \\\n",
       "0             6001        71.04     ug.m-3               1   \n",
       "1             6001        20.52     ug.m-3               1   \n",
       "2             6001         9.56     ug.m-3               1   \n",
       "3             6001         9.45     ug.m-3               1   \n",
       "4             6001        13.02     ug.m-3               1   \n",
       "\n",
       "   PM2.5-Verification  PM10-Pollutant  ...  O3-Pollutant O3-Value  O3-Unit  \\\n",
       "0                   1               5  ...             7    43.17   ug.m-3   \n",
       "1                   1               5  ...             7    57.15   ug.m-3   \n",
       "2                   1               5  ...             7    63.31   ug.m-3   \n",
       "3                   1               5  ...             7    63.18   ug.m-3   \n",
       "4                   1               5  ...             7    61.70   ug.m-3   \n",
       "\n",
       "   O3-Validity  O3-Verification  SO2-Pollutant SO2-Value  SO2-Unit  \\\n",
       "0            1                1              1     12.18    ug.m-3   \n",
       "1            1                1              1      4.65    ug.m-3   \n",
       "2            1                1              1      1.33    ug.m-3   \n",
       "3            1                1              1      1.33    ug.m-3   \n",
       "4            1                1              1      1.33    ug.m-3   \n",
       "\n",
       "   SO2-Validity  SO2-Verification  \n",
       "0             1                 1  \n",
       "1             1                 1  \n",
       "2             1                 1  \n",
       "3             1                 1  \n",
       "4             1                 1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mb.get_cleaned_datetime_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Timestamp</th>\n",
       "      <th>End_Timestamp</th>\n",
       "      <th>End</th>\n",
       "      <th>PM2.5-Pollutant</th>\n",
       "      <th>PM2.5-Value</th>\n",
       "      <th>PM2.5-Unit</th>\n",
       "      <th>PM2.5-Validity</th>\n",
       "      <th>PM2.5-Verification</th>\n",
       "      <th>PM10-Pollutant</th>\n",
       "      <th>PM10-Value</th>\n",
       "      <th>...</th>\n",
       "      <th>O3-Pollutant</th>\n",
       "      <th>O3-Value</th>\n",
       "      <th>O3-Unit</th>\n",
       "      <th>O3-Validity</th>\n",
       "      <th>O3-Verification</th>\n",
       "      <th>SO2-Pollutant</th>\n",
       "      <th>SO2-Value</th>\n",
       "      <th>SO2-Unit</th>\n",
       "      <th>SO2-Validity</th>\n",
       "      <th>SO2-Verification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:00</th>\n",
       "      <td>1356998400</td>\n",
       "      <td>1357002000</td>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>71.04</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>88.96</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>43.17</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.18</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 01:00:00</th>\n",
       "      <td>1357002000</td>\n",
       "      <td>1357005600</td>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>20.52</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.17</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>57.15</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.65</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 02:00:00</th>\n",
       "      <td>1357005600</td>\n",
       "      <td>1357009200</td>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>9.56</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.97</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>63.31</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 03:00:00</th>\n",
       "      <td>1357009200</td>\n",
       "      <td>1357012800</td>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>9.45</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.73</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>63.18</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 04:00:00</th>\n",
       "      <td>1357012800</td>\n",
       "      <td>1357016400</td>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>6001</td>\n",
       "      <td>13.02</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15.88</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>61.70</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>ug.m-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Start_Timestamp  End_Timestamp                  End  \\\n",
       "Start                                                                      \n",
       "2013-01-01 00:00:00       1356998400     1357002000  2013-01-01 01:00:00   \n",
       "2013-01-01 01:00:00       1357002000     1357005600  2013-01-01 02:00:00   \n",
       "2013-01-01 02:00:00       1357005600     1357009200  2013-01-01 03:00:00   \n",
       "2013-01-01 03:00:00       1357009200     1357012800  2013-01-01 04:00:00   \n",
       "2013-01-01 04:00:00       1357012800     1357016400  2013-01-01 05:00:00   \n",
       "\n",
       "                     PM2.5-Pollutant  PM2.5-Value PM2.5-Unit  PM2.5-Validity  \\\n",
       "Start                                                                          \n",
       "2013-01-01 00:00:00             6001        71.04     ug.m-3               1   \n",
       "2013-01-01 01:00:00             6001        20.52     ug.m-3               1   \n",
       "2013-01-01 02:00:00             6001         9.56     ug.m-3               1   \n",
       "2013-01-01 03:00:00             6001         9.45     ug.m-3               1   \n",
       "2013-01-01 04:00:00             6001        13.02     ug.m-3               1   \n",
       "\n",
       "                     PM2.5-Verification  PM10-Pollutant  PM10-Value  ...  \\\n",
       "Start                                                                ...   \n",
       "2013-01-01 00:00:00                   1               5       88.96  ...   \n",
       "2013-01-01 01:00:00                   1               5       25.17  ...   \n",
       "2013-01-01 02:00:00                   1               5       11.97  ...   \n",
       "2013-01-01 03:00:00                   1               5       11.73  ...   \n",
       "2013-01-01 04:00:00                   1               5       15.88  ...   \n",
       "\n",
       "                    O3-Pollutant  O3-Value  O3-Unit  O3-Validity  \\\n",
       "Start                                                              \n",
       "2013-01-01 00:00:00            7     43.17   ug.m-3            1   \n",
       "2013-01-01 01:00:00            7     57.15   ug.m-3            1   \n",
       "2013-01-01 02:00:00            7     63.31   ug.m-3            1   \n",
       "2013-01-01 03:00:00            7     63.18   ug.m-3            1   \n",
       "2013-01-01 04:00:00            7     61.70   ug.m-3            1   \n",
       "\n",
       "                     O3-Verification SO2-Pollutant  SO2-Value  SO2-Unit  \\\n",
       "Start                                                                     \n",
       "2013-01-01 00:00:00                1             1      12.18    ug.m-3   \n",
       "2013-01-01 01:00:00                1             1       4.65    ug.m-3   \n",
       "2013-01-01 02:00:00                1             1       1.33    ug.m-3   \n",
       "2013-01-01 03:00:00                1             1       1.33    ug.m-3   \n",
       "2013-01-01 04:00:00                1             1       1.33    ug.m-3   \n",
       "\n",
       "                     SO2-Validity  SO2-Verification  \n",
       "Start                                                \n",
       "2013-01-01 00:00:00             1                 1  \n",
       "2013-01-01 01:00:00             1                 1  \n",
       "2013-01-01 02:00:00             1                 1  \n",
       "2013-01-01 03:00:00             1                 1  \n",
       "2013-01-01 04:00:00             1                 1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.set_start_index(df, 'Start')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exponential Smooting\n",
    "\n",
    "Exponential smoothing is a family of forecasting methods that apply weighted averages of past observations to forecast future values. The weights decrease exponentially as the observations get older, hence the name. Exponential smoothing methods can be adapted to both seasonality and trend, but they do not require either to be present in the time series data.\n",
    "\n",
    "\n",
    "**Simple Exponential Smoothing:** This method is suitable for time series without trend and seasonality. It forecasts the future values based on a weighted average of past observations, with the weights declining exponentially as the observations get older.\n",
    "\n",
    "**Holtâ€™s Linear Trend Method (Double Exponential Smoothing):** This method extends simple exponential smoothing to capture linear trends in the data. It uses two smoothing equations: one for the level (the average value) and one for the trend.\n",
    "\n",
    "**Holt-Wintersâ€™ Seasonal Method (Triple Exponential Smoothing):** This method further extends exponential smoothing to capture seasonality in addition to level and trend. It incorporates a third smoothing equation for the seasonal component. There are two variations of Holt-Winters' method: the additive version for time series with a stable seasonal pattern regardless of the level, and the multiplicative version for when the seasonal pattern varies with the level of the time series.\n",
    "\n",
    "* For a time series with no trend and no seasonality, simple exponential smoothing is appropriate.\n",
    "* For a time series with a trend but no seasonality, Holtâ€™s method is appropriate.\n",
    "* For a time series with both trend and seasonality, Holt-Wintersâ€™ method is appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Defining Target and feature variables\n",
    "X,y = mb.define_target_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Principle Component Analysis (PCA)\n",
    "Principal Component Analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply PCA on the scaled data\n",
    "# pca = mb.init_pca()\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# principalDf = pd.DataFrame(data=principalComponents, index=df.index)\n",
    "\n",
    "# print(principalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Combine PCA components with the target\n",
    "# finalDf = pd.concat([principalDf, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Splitting Data \n",
    "\n",
    "Train, Validation and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = mb.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the features\n",
    "X_train, X_val, X_test = mb.extract_features(train_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable\n",
    "y_train, y_val, y_test = mb.extract_target(train_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Creation\n",
    "* Initialize Linear Regression Model\n",
    "* Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize and train the exponential smoothing model\n",
    "model = exps.init_fit_model(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation \n",
    "\n",
    "## With Validation Data\n",
    "\n",
    "Error metrics MAE, MSE, RMSE, MASE, MAPE\n",
    "\n",
    "* Regarding the MASE metric, calculating it requires a baseline prediction model for the time series, which is typically done by using the last observed value to predict the next (in the simplest case) or using more complex methods like ARIMA for one-step ahead forecasting. This is not included in the above script as it would require additional steps to implement the naive forecasting method for a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predict Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "# y_val_pred = model.predict(start=validation_data.index[0], end=validation_data.index[-1])\n",
    "# print(y_val_pred)\n",
    "\n",
    "y_val_pred = model.forecast(len(validation_data))\n",
    "print(y_val_pred)\n",
    "\n",
    "print(validation_data.index[0])\n",
    "print(validation_data.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Error Metric\n",
    "\n",
    "mb.evolve_error_metrics(y_val,y_val_pred)\n",
    "mb.naive_mean_absolute_scaled_error(y_val,y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## With Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "# y_test_pred = model.predict(start=test_data.index[0], end=test_data.index[-1])\n",
    "\n",
    "y_test_pred = model.forecast(len(test_data))\n",
    "print(y_test_pred)\n",
    "\n",
    "\n",
    "print(test_data.index[0])\n",
    "print(test_data.index[-1])\n",
    "print(y_test_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Error Metric\n",
    "mb.evolve_error_metrics(y_test ,y_test_pred)\n",
    "mb.naive_mean_absolute_scaled_error(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot Table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mb.plot_pm_true_predict(validation_data, y_val_pred, 'Validation')\n",
    "mb.plot_pm_true_predict(test_data, y_test_pred, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HyperPramater Tuning\n",
    "\n",
    "Linear Regression typically has fewer hyperparameters than other models like neural networks or ensemble models. However, there are still some aspects of the model that you can adjust. For instance, you can apply regularization, which can be considered a form of hyperparameter tuning. The most common types of regularized linear regression are Ridge Regression (L2 regularization) and Lasso Regression (L1 regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with configuration (None, 'add', 12, True): Can only dampen the trend component\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/tugcekonuklar/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with configuration (None, 'mul', 12, True): Can only dampen the trend component\n",
      "Best configuration: Trend: mul, Seasonal: add, Seasonal Periods: 12, Damped: True\n",
      "Best MSE: 114.97180825533549\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define your hyperparameter grid\n",
    "trend_options = ['add', 'mul', None]\n",
    "seasonal_options = ['add', 'mul', None]\n",
    "seasonal_periods_options = [12]  # example for monthly data with yearly seasonality\n",
    "damped_options = [True, False]\n",
    "\n",
    "# Cartesian product of the hyperparameter grid\n",
    "param_grid = list(product(trend_options, seasonal_options, seasonal_periods_options, damped_options))\n",
    "\n",
    "# Keep track of the best configuration and corresponding MSE\n",
    "best_mse = float(\"inf\")\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "# Perform grid search\n",
    "for params in param_grid:\n",
    "    trend, seasonal, seasonal_periods, damped = params\n",
    "\n",
    "    # Skip if both trend and seasonal are None\n",
    "    if trend is None and seasonal is None:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Fit the model with the current set of hyperparameters\n",
    "        model = ExponentialSmoothing(\n",
    "            train_data['PM2.5-Value'], \n",
    "            seasonal_periods=seasonal_periods, \n",
    "            trend=trend, \n",
    "            seasonal=seasonal,\n",
    "            damped=damped\n",
    "        ).fit(use_boxcox=True)\n",
    "\n",
    "        # Forecast on the validation set\n",
    "        val_predictions = model.forecast(len(validation_data))\n",
    "\n",
    "        # Calculate the MSE for this model configuration\n",
    "        mse = mean_squared_error(validation_data['PM2.5-Value'], val_predictions)\n",
    "\n",
    "        # Check if this configuration gives us a lower MSE than what we've seen so far\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_config = params\n",
    "            best_model = model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with configuration {params}: {e}\")\n",
    "\n",
    "# Output the best performing model configuration\n",
    "print(f\"Best configuration: Trend: {best_config[0]}, Seasonal: {best_config[1]}, Seasonal Periods: {best_config[2]}, Damped: {best_config[3]}\")\n",
    "print(f\"Best MSE: {best_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}